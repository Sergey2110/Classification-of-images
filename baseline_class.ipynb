{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gzuv2run9Yxa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import gc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "#from torchvision.models import resnet18\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIR_TRAIN = \"/content/Classification-of-construction-equipment-objects/train/\"\n",
        "DIR_TEST = \"/content/Classification-of-construction-equipment-objects/test/\"\n",
        "\n",
        "PATH_TRAIN = DIR_TRAIN + \"train.csv\"\n",
        "PATH_TEST = DIR_TEST + \"test.csv\""
      ],
      "metadata": {
        "id": "JtcHBYJ9oxVx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/Sergey2110/Classification-of-construction-equipment-objects.git\n",
        "%cd Classification-of-construction-equipment-objects"
      ],
      "metadata": {
        "id": "puFPw94J3f_o",
        "outputId": "dbad4478-a8bc-4129-d297-01d22f033b13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Classification-of-construction-equipment-objects'...\n",
            "remote: Enumerating objects: 7230, done.\u001b[K\n",
            "remote: Counting objects: 100% (7230/7230), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7216/7216), done.\u001b[K\n",
            "remote: Total 7230 (delta 43), reused 7172 (delta 10), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (7230/7230), 30.06 MiB | 15.27 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "/content/Classification-of-construction-equipment-objects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "8LotOtK-sFsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, data_df, transform=None):\n",
        "        self.data_df = data_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # достаем имя изображения и ее лейбл\n",
        "        image_name, label = self.data_df.iloc[idx]['ID_img'], self.data_df.iloc[idx]['class']\n",
        "\n",
        "        # читаем картинку. read the image\n",
        "        image = cv2.imread(DIR_TRAIN + f\"{image_name}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        # преобразуем, если нужно. transform it, if necessary\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)"
      ],
      "metadata": {
        "id": "h72XzlyfMZek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, data_df, transform=None):\n",
        "        self.data_df = data_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.data_df.iloc[idx]['ID_img']\n",
        "\n",
        "        # читаем картинку\n",
        "        image = cv2.imread(DIR_TEST + f\"{image_name}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        # преобразуем, если нужно\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)"
      ],
      "metadata": {
        "id": "7URcg7KlMqbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import activation\n",
        "class Classification:\n",
        "    def __init__(self):\n",
        "        print(\"Обучающей выборки \", len(os.listdir(DIR_TRAIN)))\n",
        "        print(\"Тестовой выборки \", len(os.listdir(DIR_TEST)))\n",
        "\n",
        "        gc.collect()\n",
        "        torch.manual_seed(0)\n",
        "        torch.cuda.manual_seed(0)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "        # задаем преобразование изображения.\n",
        "        self.train_transform = transforms.Compose([\n",
        "            # transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        self.valid_transform = transforms.Compose([\n",
        "            # transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        self.data_df = pd.read_csv(PATH_TRAIN)\n",
        "        self.data_df = self.data_df[:2000]\n",
        "        # self.data_df.head(3)\n",
        "\n",
        "        # разделим датасет на трейн и валидацию, чтобы смотреть на качество\n",
        "        self.train_df, self.valid_df = train_test_split(self.data_df, test_size=0.2)\n",
        "        train_dataset = ImageDataset(self.train_df, self.train_transform)\n",
        "        valid_dataset = ImageDataset(self.valid_df, self.valid_transform)\n",
        "\n",
        "        self.train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                                        batch_size=5,\n",
        "                                                        shuffle=True,\n",
        "                                                        pin_memory=True,\n",
        "                                                        num_workers=2)\n",
        "\n",
        "        self.valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
        "                                                        batch_size=5,\n",
        "                                                        shuffle=True,\n",
        "                                                        pin_memory=True,\n",
        "                                                        num_workers=2)\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.dict_acc_for_batch = {\"train\": {}, \"test\": {}}\n",
        "        self.dict_loss_for_batch = {\"train\": {}, \"test\": {}}\n",
        "\n",
        "    def crossvalid(self, res_model=None, criterion=None, optimizer=None, dataset=None, k_fold=5):\n",
        "        train_score = pd.Series()\n",
        "        val_score = pd.Series()\n",
        "\n",
        "        total_size = len(dataset)\n",
        "        fraction = 1 / k_fold\n",
        "        seg = int(total_size * fraction)\n",
        "        # tr:train,val:valid; r:right,l:left;  eg: trrr: right index of right side train subset\n",
        "        # index: [trll,trlr],[vall,valr],[trrl,trrr]\n",
        "        for i in range(k_fold):\n",
        "            trll = 0\n",
        "            trlr = i * seg\n",
        "            vall = trlr\n",
        "            valr = i * seg + seg\n",
        "            trrl = valr\n",
        "            trrr = total_size\n",
        "\n",
        "            train_left_indices = list(range(trll, trlr))\n",
        "            train_right_indices = list(range(trrl, trrr))\n",
        "\n",
        "            train_indices = train_left_indices + train_right_indices\n",
        "            val_indices = list(range(vall, valr))\n",
        "\n",
        "            train_set = torch.utils.data.dataset.Subset(dataset, train_indices)\n",
        "            val_set = torch.utils.data.dataset.Subset(dataset, val_indices)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(train_set, batch_size=50,\n",
        "                                                       shuffle=True, num_workers=4)\n",
        "            val_loader = torch.utils.data.DataLoader(val_set, batch_size=50,\n",
        "                                                     shuffle=True, num_workers=4)\n",
        "            train_acc = self.train(res_model, criterion, optimizer, train_loader, val_loader, 1)\n",
        "            train_score.at[i] = train_acc\n",
        "            # val_acc = valid(res_model, criterion, optimizer, val_loader)\n",
        "            # val_score.at[i] = val_acc\n",
        "\n",
        "        return train_score, val_score\n",
        "\n",
        "    def plot_history(self, train_history, val_history, title = 'Ошибка'):\n",
        "        plt.figure()\n",
        "        plt.title('{}'.format(title))\n",
        "\n",
        "        plt.plot(train_history, label='train', zorder=1)\n",
        "        plt.plot(val_history, label='val', zorder=1)\n",
        "\n",
        "        plt.legend(loc='best')\n",
        "        plt.xlabel('steps')\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    def train(self, criterion, optimizer, train_dataloader, test_dataloader, NUM_EPOCH=15, show_img=False):\n",
        "        train_loss_log = []\n",
        "        val_loss_log = []\n",
        "        train_acc_log = []\n",
        "        val_acc_log = []\n",
        "\n",
        "        train_loss_log_for_batch = []\n",
        "        val_loss_log_for_batch = []\n",
        "        train_acc_log_for_batch = []\n",
        "        val_acc_log_for_batch = []\n",
        "\n",
        "        for epoch in tqdm(range(NUM_EPOCH)):\n",
        "            self.model.train()\n",
        "            train_loss = 0.\n",
        "            train_size = 0\n",
        "            train_pred = 0.\n",
        "\n",
        "            for imgs, labels in train_dataloader:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                imgs = imgs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                y_pred = self.model(imgs)\n",
        "\n",
        "                loss = criterion(y_pred, labels)\n",
        "                loss.backward()\n",
        "\n",
        "                train_size += y_pred.size(0)\n",
        "                train_loss += loss.item()\n",
        "                train_loss_log_for_batch.append(loss.data / y_pred.size(0))\n",
        "                train_pred += (y_pred.argmax(1) == labels).sum()\n",
        "                train_acc_log_for_batch.append(train_pred / y_pred.size(0))\n",
        "                optimizer.step()\n",
        "\n",
        "            train_loss_log.append(train_loss / train_size)\n",
        "            train_acc_log.append(train_pred.item() / train_size)\n",
        "\n",
        "            self.dict_loss_for_batch[\"train\"].update({epoch: train_loss_log_for_batch[:]})\n",
        "            self.dict_acc_for_batch[\"train\"].update({epoch: train_acc_log_for_batch[:]})\n",
        "\n",
        "            # if show_img and epoch > (epoch - 2) and train_pred / train_size < 0.9:\n",
        "            #     for j in range(4):\n",
        "            #         show_input(imgs[j].cpu(),\n",
        "            #                    title=f\"{labels[j]} {list_file[list_index_val[j + i * batch_size_v]][0]}\")\n",
        "            #         print(f\" epoch = {epoch} acc = {(train_pred / train_size) / batch_size_v}\")\n",
        "\n",
        "            val_loss = 0.\n",
        "            val_size = 0\n",
        "            val_pred = 0.\n",
        "            self.model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for imgs, labels in test_dataloader:\n",
        "                    imgs = imgs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "\n",
        "                    pred = self.model(imgs)\n",
        "                    loss = criterion(pred, labels)\n",
        "\n",
        "                    val_size += pred.size(0)\n",
        "                    val_loss += loss.item()\n",
        "                    val_loss_log_for_batch.append(loss.data / pred.size(0))\n",
        "                    val_pred += (pred.argmax(1) == labels).sum()\n",
        "                    val_acc_log_for_batch.append(val_pred / pred.size(0))\n",
        "\n",
        "            val_loss_log.append(val_loss / val_size)\n",
        "            val_acc_log.append(val_pred.item() / val_size)\n",
        "\n",
        "            self.dict_loss_for_batch[\"test\"].update({epoch: val_loss_log_for_batch[:]})\n",
        "            self.dict_acc_for_batch[\"test\"].update({epoch: val_acc_log_for_batch[:]})\n",
        "\n",
        "        # clear_output()\n",
        "\n",
        "        print(f'\\nМин. и макс. потери на тренировочных и проверочных данных: {min(train_loss_log)},  {max(train_loss_log)},  {min(val_loss_log)},  {max(val_loss_log)}')\n",
        "        print(f'Мин. и макс. верность на тренировочных и проверочных данных: {min(train_acc_log)},  {max(train_acc_log)},  {min(val_acc_log)},  {max(val_acc_log)}')\n",
        "        print(f'Потери на тренировке и проверке: {(train_loss / train_size) * 100},  {(val_loss / val_size) * 100}')\n",
        "        print(f'Верность на тренировке и проверке: {(train_pred.item() / train_size) * 100},  {(val_pred.item() / val_size) * 100}')\n",
        "\n",
        "        return train_loss_log, train_acc_log, val_loss_log, val_acc_log\n",
        "\n",
        "    def watch_img(self):\n",
        "        # посмотрим на картинки. Не забудем указать корретный путь до папки\n",
        "        sns.countplot(x=\"class\", data=self.data_df)\n",
        "        fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
        "        fig.suptitle(f'Автомобиль {\" \" * 105} Кран', fontsize=14)\n",
        "\n",
        "        for i, name in zip(range(4), self.data_df[self.data_df['class'] == 1].sample(4, random_state=42)['ID_img']):\n",
        "            img = plt.imread(DIR_TRAIN + f\"{name}\")\n",
        "            axs[i // 2, (i % 2)].imshow(img)\n",
        "            axs[i // 2, (i % 2)].axis('off')\n",
        "\n",
        "        for i, name in zip(range(4), self.data_df[self.data_df['class'] == 0].sample(4, random_state=42)['ID_img']):\n",
        "            img = plt.imread(DIR_TRAIN + f\"{name}\")\n",
        "            axs[i // 2, (i % 2) + 2].imshow(img)\n",
        "            axs[i // 2, (i % 2) + 2].axis('off')\n",
        "\n",
        "        fig.tight_layout()\n",
        "        fig.subplots_adjust(top=0.88)\n",
        "\n",
        "    def train_model(self, epoch=5):\n",
        "        self.model = models.resnet152(pretrained=True)\n",
        "        self.model.fc = nn.Linear(2048, 8)\n",
        "        # self.model.fc = nn.Softmax(2048, 8)\n",
        "        self.model = self.model.to(self.device)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=0.01)\n",
        "        train_loss_log, train_acc_log, val_loss_log, val_acc_log = self.train(criterion,\n",
        "                                                                              optimizer,\n",
        "                                                                              self.train_loader,\n",
        "                                                                              self.valid_loader,\n",
        "                                                                              epoch)\n",
        "        return train_loss_log, train_acc_log, val_loss_log, val_acc_log\n",
        "\n",
        "    def train_model2(self, epoch=5):\n",
        "        self.model = models.resnet152(pretrained=True, activation='Softmax')\n",
        "        self.model.fc = nn.Linear(2048, 8)\n",
        "        # self.model.fc = nn.Softmax(2048, 8)\n",
        "        self.model = self.model.to(self.device)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=0.01)\n",
        "        train_loss_log, train_acc_log, val_loss_log, val_acc_log = self.train(criterion,\n",
        "                                                                              optimizer,\n",
        "                                                                              self.train_loader,\n",
        "                                                                              self.valid_loader,\n",
        "                                                                              epoch)\n",
        "        return train_loss_log, train_acc_log, val_loss_log, val_acc_log\n",
        "\n",
        "    def evaluation_model(self):\n",
        "        valid_predicts = []\n",
        "        self.model.eval()\n",
        "        for imgs, _ in tqdm(self.valid_loader):\n",
        "            imgs = imgs.to(self.device)\n",
        "            pred = self.model(imgs)\n",
        "            pred_numpy = pred.cpu().detach().numpy()\n",
        "            for class_obj in pred_numpy:\n",
        "                index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
        "                valid_predicts.append(index)\n",
        "        self.valid_df[\"pred\"] = valid_predicts\n",
        "        val_accuracy = recall_score(self.valid_df['class'].values, self.valid_df['pred'].values, average=\"macro\")\n",
        "        print(f\"Validation accuracy = {val_accuracy}\")\n",
        "\n",
        "        self.test_df = pd.read_csv(PATH_TEST)\n",
        "        self.test_df = self.test_df.drop([\"class\"], axis=1)\n",
        "        self.test_dataset = TestImageDataset(self.test_df, self.valid_transform)\n",
        "        self.test_loader = torch.utils.data.DataLoader(dataset=self.test_dataset,\n",
        "                                                       batch_size=32,\n",
        "                                                       # shuffle=True,\n",
        "                                                       pin_memory=True,\n",
        "                                                       num_workers=2)\n",
        "\n",
        "    def create_submit(self):\n",
        "        self.model.eval()\n",
        "        predicts = []\n",
        "        for imgs in tqdm(self.test_loader):\n",
        "            imgs = imgs.to(self.device)\n",
        "            pred = self.model(imgs)\n",
        "            for class_obj in pred:\n",
        "                index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
        "                predicts.append(index)\n",
        "\n",
        "        self.test_df[\"class\"] = predicts\n",
        "        self.test_df.head()\n",
        "        self.test_df.to_csv(\"submit.csv\", index=False)"
      ],
      "metadata": {
        "id": "WTzOYXnLr615"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification = Classification()\n",
        "# print(list(classification.train_loader))\n",
        "train_loss_log, train_acc_log, val_loss_log, val_acc_log = classification.train_model(epoch=20)\n",
        "train_loss_log, train_acc_log, val_loss_log, val_acc_log = classification.train_model2(epoch=20)\n",
        "# classification.plot_history(train_loss_log, val_loss_log)\n",
        "# classification.plot_history(train_acc_log, val_acc_log, 'Верность')\n",
        "# classification.evaluation_model()\n",
        "# classification.create_submit()"
      ],
      "metadata": {
        "id": "NtXeREGor-ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59c4b8a-14c5-4056-c1d7-6346701fcbf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающей выборки  4993\n",
            "Тестовой выборки  2141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100%|██████████| 230M/230M [00:08<00:00, 29.0MB/s]\n",
            "100%|██████████| 3/3 [04:05<00:00, 81.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Мин. и макс. потери на тренировочных и проверочных данных: 0.5922056809873368,  0.7162120244667585,  0.3067720456750021,  0.418225834336659\n",
            "Мин. и макс. верность на тренировочных и проверочных данных: 0.516875,  0.6325,  0.745,  0.7875\n",
            "Потери на тренировке и проверке: 71.62120244667585,  30.677204567500212\n",
            "Верность на тренировке и проверке: 63.24999999999999,  78.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification.model)"
      ],
      "metadata": {
        "id": "fl14sRYstX0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights = []\n",
        "conv_layers = []\n",
        "counter = 0\n",
        "num_layer = 12\n",
        "\n",
        "model_children = list(classification.model.cpu().children())\n",
        "\n",
        "for i in range(len(model_children)):\n",
        "  if type(model_children[i]) == nn.Conv2d:\n",
        "    counter += 1\n",
        "    model_weights.append(model_children[i].weight)\n",
        "    conv_layers.append(model_children[i])\n",
        "  elif type(model_children[i]) == nn.Sequential:\n",
        "    for j in range(len(model_children[i])):\n",
        "      for child in model_children[i][j].children():\n",
        "        if type(child) == nn.Conv2d:\n",
        "          counter += 1\n",
        "          model_weights.append(child.weight)\n",
        "          conv_layers.append(child)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for num_layer in range(len(model_weights)):\n",
        "  for i, filter in enumerate(model_weights[num_layer]):\n",
        "    if i == 16 or filter.shape[-1] == 1:\n",
        "      break\n",
        "    plt.subplot(16, 16, i+1)\n",
        "    plt.imshow(filter[0, :, :].detach(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "LH8PhGIhoTJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for weight, conv in zip(model_weights, conv_layers):\n",
        "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")"
      ],
      "metadata": {
        "id": "fTqb6_872Gew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(f\"{DIR_TEST}/0.jpg\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "transform = transforms.Compose([\n",
        " transforms.ToPILImage(),\n",
        " transforms.Resize((512, 512)),\n",
        " transforms.ToTensor(),\n",
        "])\n",
        "img = np.array(img)\n",
        "img = transform(img)\n",
        "img = img.unsqueeze(0)\n",
        "\n",
        "results = [conv_layers[0](img)]\n",
        "for i in range(1, len(conv_layers)):\n",
        "  results.append(conv_layers[i](results[-1]))\n",
        "outputs = results\n",
        "\n",
        "for num_layer in range(len(outputs)):\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  layer_viz = outputs[num_layer][0, :, :, :]\n",
        "  layer_viz = layer_viz.data\n",
        "  for i, filter in enumerate(layer_viz):\n",
        "    if i == 64:\n",
        "      break\n",
        "    plt.subplot(7, 10, i + 1)\n",
        "    plt.imshow(filter, cmap='gray')\n",
        "    plt.axis(\"off\")\n",
        "  plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "Ixg6Vz6UaV6a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}