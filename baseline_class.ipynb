{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gzuv2run9Yxa"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import cv2\n",
        "import gc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIR_TRAIN = \"/content/Classification-of-construction-equipment-objects/train/\"\n",
        "DIR_TEST = \"/content/Classification-of-construction-equipment-objects/test/\"\n",
        "\n",
        "PATH_TRAIN = DIR_TRAIN + \"train.csv\"\n",
        "PATH_TEST = DIR_TEST + \"test.csv\""
      ],
      "metadata": {
        "id": "JtcHBYJ9oxVx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/Sergey2110/Classification-of-construction-equipment-objects.git\n",
        "%cd Classification-of-construction-equipment-objects"
      ],
      "metadata": {
        "id": "puFPw94J3f_o",
        "outputId": "284fb7fc-c5e2-406a-fb9b-ed4ce1e0bbd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Classification-of-construction-equipment-objects' already exists and is not an empty directory.\n",
            "/content/Classification-of-construction-equipment-objects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "warnings.simplefilter('ignore')\n",
        "gc.collect()\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "8LotOtK-sFsV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, data_df, transform=None):\n",
        "        self.data_df = data_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name, label = self.data_df.iloc[idx]['ID_img'], self.data_df.iloc[idx]['class']\n",
        "\n",
        "        image = cv2.imread(DIR_TRAIN + f\"{image_name}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)"
      ],
      "metadata": {
        "id": "h72XzlyfMZek"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classification:\n",
        "    def __init__(self):\n",
        "        print(\"Обучающей выборки \", len(os.listdir(DIR_TRAIN)))\n",
        "        print(\"Тестовой выборки \", len(os.listdir(DIR_TEST)))\n",
        "\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            # transforms.RandomResizedCrop(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        self.valid_transform = transforms.Compose([\n",
        "            # transforms.Resize((256, 256)),\n",
        "            transforms.RandomResizedCrop(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        self.data_df = pd.read_csv(PATH_TRAIN)\n",
        "\n",
        "        self.train_df, self.valid_df = train_test_split(self.data_df, test_size=0.2)\n",
        "        train_dataset = ImageDataset(self.train_df, self.train_transform)\n",
        "        valid_dataset = ImageDataset(self.valid_df, self.valid_transform)\n",
        "\n",
        "        self.train_loader = DataLoader(dataset=train_dataset, batch_size=5, shuffle=False, num_workers=8)\n",
        "\n",
        "        self.valid_loader = DataLoader(dataset=valid_dataset, batch_size=5, shuffle=False, num_workers=8)\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.dict_acc_for_batch = {\"train\": {}, \"test\": {}}\n",
        "        self.dict_loss_for_batch = {\"train\": {}, \"test\": {}}\n",
        "\n",
        "\n",
        "    def plot_history(self, train_history, val_history, title = 'Ошибка'):\n",
        "        plt.figure()\n",
        "        plt.title('{}'.format(title))\n",
        "\n",
        "        plt.plot(train_history, label='train', zorder=1)\n",
        "        plt.plot(val_history, label='val', zorder=1)\n",
        "\n",
        "        plt.legend(loc='best')\n",
        "        plt.xlabel('steps')\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def watch_img(self):\n",
        "        sns.countplot(x=\"class\", data=self.data_df)\n",
        "        fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
        "        fig.suptitle(f'Автомобиль {\" \" * 105} Кран', fontsize=14)\n",
        "\n",
        "        for i, name in zip(range(4), self.data_df[self.data_df['class'] == 1].sample(4, random_state=42)['ID_img']):\n",
        "            img = plt.imread(DIR_TRAIN + f\"{name}\")\n",
        "            axs[i // 2, (i % 2)].imshow(img)\n",
        "            axs[i // 2, (i % 2)].axis('off')\n",
        "\n",
        "        for i, name in zip(range(4), self.data_df[self.data_df['class'] == 0].sample(4, random_state=42)['ID_img']):\n",
        "            img = plt.imread(DIR_TRAIN + f\"{name}\")\n",
        "            axs[i // 2, (i % 2) + 2].imshow(img)\n",
        "            axs[i // 2, (i % 2) + 2].axis('off')\n",
        "\n",
        "        fig.tight_layout()\n",
        "        fig.subplots_adjust(top=0.88)\n",
        "\n",
        "    def crossvalid(self, dataset, batch_size=5, n_splits=5, NUM_EPOCH=15):\n",
        "        train_loss_log, val_loss_log = [], []\n",
        "        train_acc_log, val_acc_log = [], []\n",
        "        train_loss_log_for_batch, val_loss_log_for_batch = [], []\n",
        "        train_acc_log_for_batch, val_acc_log_for_batch = [], []\n",
        "\n",
        "        self.model = models.resnet152(pretrained=True)\n",
        "        self.model.fc = nn.Linear(2048, 8)\n",
        "        self.model = self.model.to(self.device)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=0.01)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
        "        kf = KFold(n_splits)\n",
        "        cros_dataset = ImageDataset(dataset, self.train_transform)\n",
        "\n",
        "        for _fold, (train_index, valid_index) in enumerate(kf.split(cros_dataset)):\n",
        "            train_dataset = Subset(cros_dataset, train_index)\n",
        "            train_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
        "            valid_dataset   = Subset(cros_dataset, valid_index)\n",
        "            valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle=False)\n",
        "\n",
        "            for epoch in tqdm(range(NUM_EPOCH)):\n",
        "                self.model.train()\n",
        "                train_loss = 0.\n",
        "                train_size = 0\n",
        "                train_pred = 0.\n",
        "\n",
        "                scheduler.step()\n",
        "                for imgs, labels in train_dataloader:\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    imgs = imgs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "                    y_pred = self.model(imgs)\n",
        "\n",
        "                    loss = criterion(y_pred, labels)\n",
        "                    loss.backward()\n",
        "\n",
        "                    train_size += y_pred.size(0)\n",
        "                    train_loss += loss.item()\n",
        "                    train_loss_log_for_batch.append(loss.data / y_pred.size(0))\n",
        "                    train_pred += (y_pred.argmax(1) == labels).sum()\n",
        "                    train_acc_log_for_batch.append(train_pred / y_pred.size(0))\n",
        "                    optimizer.step()\n",
        "\n",
        "                train_loss_log.append(train_loss / train_size)\n",
        "                train_acc_log.append(train_pred.item() / train_size)\n",
        "\n",
        "                self.dict_loss_for_batch[\"train\"].update({epoch: train_loss_log_for_batch[:]})\n",
        "                self.dict_acc_for_batch[\"train\"].update({epoch: train_acc_log_for_batch[:]})\n",
        "\n",
        "                # if show_img and epoch > (epoch - 2) and train_pred / train_size < 0.9:\n",
        "                # for j in range(4):\n",
        "                #     self.show_input(imgs[j].cpu(), title=f\"{labels[j]} {list_file[list_index_val[j + i * batch_size_v]][0]}\")\n",
        "                #     print(f\" epoch = {epoch} acc = {(train_pred / train_size) / 5}\")\n",
        "\n",
        "                val_loss = 0.\n",
        "                val_size = 0\n",
        "                val_pred = 0.\n",
        "                self.model.eval()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for imgs, labels in valid_dataloader:\n",
        "                        imgs = imgs.to(self.device)\n",
        "                        labels = labels.to(self.device)\n",
        "\n",
        "                        pred = self.model(imgs)\n",
        "                        loss = criterion(pred, labels)\n",
        "\n",
        "                        val_size += pred.size(0)\n",
        "                        val_loss += loss.item()\n",
        "                        val_loss_log_for_batch.append(loss.data / pred.size(0))\n",
        "                        val_pred += (pred.argmax(1) == labels).sum()\n",
        "                        val_acc_log_for_batch.append(val_pred / pred.size(0))\n",
        "\n",
        "                val_loss_log.append(val_loss / val_size)\n",
        "                val_acc_log.append(val_pred.item() / val_size)\n",
        "\n",
        "                self.dict_loss_for_batch[\"test\"].update({epoch: val_loss_log_for_batch[:]})\n",
        "                self.dict_acc_for_batch[\"test\"].update({epoch: val_acc_log_for_batch[:]})\n",
        "\n",
        "\n",
        "        log_loss_acc = pd.DataFrame({\"Верность (min/max)\": [f\"{min(train_acc_log)}/{max(train_acc_log)}\", f\"{min(val_acc_log)}/{max(val_acc_log)}\"],\n",
        "                                     \"Потери (min/max)\": [f\"{min(train_loss_log)}/{max(train_loss_log)}\", f\"{min(val_loss_log)}/{max(val_loss_log)}\"]\n",
        "                                    }, index=[\"Тренировка\",\"Проверка\"])\n",
        "        print(log_loss_acc)\n",
        "\n",
        "        return log_loss_acc\n",
        "\n",
        "    def train(self, criterion, optimizer, scheduler, train_dataloader, test_dataloader, NUM_EPOCH=15, show_img=False):\n",
        "        train_loss_log, val_loss_log = [], []\n",
        "        train_acc_log, val_acc_log = [], []\n",
        "        train_loss_log_for_batch, val_loss_log_for_batch = [], []\n",
        "        train_acc_log_for_batch, val_acc_log_for_batch = [], []\n",
        "\n",
        "        self.model = models.resnet152(pretrained=True)\n",
        "        self.model.fc = nn.Linear(2048, 8)\n",
        "        self.model = self.model.to(self.device)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=0.01)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
        "\n",
        "        for epoch in tqdm(range(NUM_EPOCH)):\n",
        "            self.model.train()\n",
        "            train_loss = 0.\n",
        "            train_size = 0\n",
        "            train_pred = 0.\n",
        "\n",
        "            scheduler.step()\n",
        "            for imgs, labels in train_dataloader:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                imgs = imgs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                y_pred = self.model(imgs)\n",
        "\n",
        "                loss = criterion(y_pred, labels)\n",
        "                loss.backward()\n",
        "\n",
        "                train_size += y_pred.size(0)\n",
        "                train_loss += loss.item()\n",
        "                train_loss_log_for_batch.append(loss.data / y_pred.size(0))\n",
        "                train_pred += (y_pred.argmax(1) == labels).sum()\n",
        "                train_acc_log_for_batch.append(train_pred / y_pred.size(0))\n",
        "                optimizer.step()\n",
        "\n",
        "            train_loss_log.append(train_loss / train_size)\n",
        "            train_acc_log.append(train_pred.item() / train_size)\n",
        "\n",
        "            self.dict_loss_for_batch[\"train\"].update({epoch: train_loss_log_for_batch[:]})\n",
        "            self.dict_acc_for_batch[\"train\"].update({epoch: train_acc_log_for_batch[:]})\n",
        "\n",
        "            # if show_img and epoch > (epoch - 2) and train_pred / train_size < 0.9:\n",
        "            # for j in range(4):\n",
        "            #     self.show_input(imgs[j].cpu(), title=f\"{labels[j]} {list_file[list_index_val[j + i * batch_size_v]][0]}\")\n",
        "            #     print(f\" epoch = {epoch} acc = {(train_pred / train_size) / 5}\")\n",
        "\n",
        "            val_loss = 0.\n",
        "            val_size = 0\n",
        "            val_pred = 0.\n",
        "            self.model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for imgs, labels in test_dataloader:\n",
        "                    imgs = imgs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "\n",
        "                    pred = self.model(imgs)\n",
        "                    loss = criterion(pred, labels)\n",
        "\n",
        "                    val_size += pred.size(0)\n",
        "                    val_loss += loss.item()\n",
        "                    val_loss_log_for_batch.append(loss.data / pred.size(0))\n",
        "                    val_pred += (pred.argmax(1) == labels).sum()\n",
        "                    val_acc_log_for_batch.append(val_pred / pred.size(0))\n",
        "\n",
        "            val_loss_log.append(val_loss / val_size)\n",
        "            val_acc_log.append(val_pred.item() / val_size)\n",
        "\n",
        "            self.dict_loss_for_batch[\"test\"].update({epoch: val_loss_log_for_batch[:]})\n",
        "            self.dict_acc_for_batch[\"test\"].update({epoch: val_acc_log_for_batch[:]})\n",
        "\n",
        "        log_loss_acc = pd.DataFrame({\"Верность (min/max)\": [f\"{min(train_acc_log)}/{max(train_acc_log)}\", f\"{min(val_acc_log)}/{max(val_acc_log)}\"],\n",
        "                             \"Потери (min/max)\": [f\"{min(train_loss_log)}/{max(train_loss_log)}\", f\"{min(val_loss_log)}/{max(val_loss_log)}\"]\n",
        "                            }, index=[\"Тренировка\",\"Проверка\"])\n",
        "        print(log_loss_acc)\n",
        "\n",
        "        return log_loss_acc\n",
        "\n",
        "    def evaluation_model(self):\n",
        "        valid_predicts = []\n",
        "        self.model.eval()\n",
        "        for imgs, _ in tqdm(self.valid_loader):\n",
        "            imgs = imgs.to(self.device)\n",
        "            pred = self.model(imgs)\n",
        "            pred_numpy = pred.cpu().detach().numpy()\n",
        "            for class_obj in pred_numpy:\n",
        "                index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
        "                valid_predicts.append(index)\n",
        "        self.valid_df[\"pred\"] = valid_predicts\n",
        "        val_accuracy = recall_score(self.valid_df['class'].values, self.valid_df['pred'].values, average=\"macro\")\n",
        "        print(f\"Верность = {val_accuracy}\")\n",
        "\n",
        "        self.test_df = pd.read_csv(PATH_TEST)\n",
        "        self.test_df = self.test_df.drop([\"class\"], axis=1)\n",
        "        self.test_dataset = ImageDataset(self.test_df, self.valid_transform)\n",
        "        self.test_loader = torch.utils.data.DataLoader(dataset=self.test_dataset,\n",
        "                                                       batch_size=32,\n",
        "                                                       shuffle=True,\n",
        "                                                       pin_memory=True,\n",
        "                                                       num_workers=2)\n",
        "\n",
        "    def create_submit(self):\n",
        "        self.model.eval()\n",
        "        predicts = []\n",
        "        for imgs in tqdm(self.test_loader):\n",
        "            imgs = imgs.to(self.device)\n",
        "            pred = self.model(imgs)\n",
        "            for class_obj in pred:\n",
        "                index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
        "                predicts.append(index)\n",
        "\n",
        "        self.test_df[\"class\"] = predicts\n",
        "        self.test_df.head()\n",
        "        self.test_df.to_csv(\"submit.csv\", index=False)"
      ],
      "metadata": {
        "id": "WTzOYXnLr615"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification = Classification()\n",
        "start = time.time()\n",
        "log_loss_acc = classification.crossvalid(classification.data_df, NUM_EPOCH=3)\n",
        "print(f'{(time.time() - start)//60:.0f}мин {(time.time() - start)%50:.0f}с')\n",
        "# classification.train_model(epoch=1)"
      ],
      "metadata": {
        "id": "Znyiu1ioxZQA",
        "outputId": "e06600c2-0f77-4b45-9ca5-50201240c280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающей выборки  4993\n",
            "Тестовой выборки  2141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights = []\n",
        "conv_layers = []\n",
        "counter = 0\n",
        "num_layer = 12\n",
        "\n",
        "model_children = list(classification.model.cpu().children())\n",
        "\n",
        "for i in range(len(model_children)):\n",
        "  if type(model_children[i]) == nn.Conv2d:\n",
        "    counter += 1\n",
        "    model_weights.append(model_children[i].weight)\n",
        "    conv_layers.append(model_children[i])\n",
        "  elif type(model_children[i]) == nn.Sequential:\n",
        "    for j in range(len(model_children[i])):\n",
        "      for child in model_children[i][j].children():\n",
        "        if type(child) == nn.Conv2d:\n",
        "          counter += 1\n",
        "          model_weights.append(child.weight)\n",
        "          conv_layers.append(child)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for num_layer in range(len(model_weights)):\n",
        "  for i, filter in enumerate(model_weights[num_layer]):\n",
        "    if i == 16 or filter.shape[-1] == 1:\n",
        "      break\n",
        "    plt.subplot(16, 16, i+1)\n",
        "    plt.imshow(filter[0, :, :].detach(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "LH8PhGIhoTJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "97be3d55-46eb-4690-e931-4f7eb380468b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3b78978b256d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_children\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_children\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'classification' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for weight, conv in zip(model_weights, conv_layers):\n",
        "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")"
      ],
      "metadata": {
        "id": "fTqb6_872Gew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(f\"{DIR_TEST}/0.jpg\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "transform = transforms.Compose([\n",
        " transforms.ToPILImage(),\n",
        " transforms.Resize((512, 512)),\n",
        " transforms.ToTensor(),\n",
        "])\n",
        "img = np.array(img)\n",
        "img = transform(img)\n",
        "img = img.unsqueeze(0)\n",
        "\n",
        "results = [conv_layers[0](img)]\n",
        "for i in range(1, len(conv_layers)):\n",
        "  results.append(conv_layers[i](results[-1]))\n",
        "outputs = results\n",
        "\n",
        "for num_layer in range(len(outputs)):\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  layer_viz = outputs[num_layer][0, :, :, :]\n",
        "  layer_viz = layer_viz.data\n",
        "  for i, filter in enumerate(layer_viz):\n",
        "    if i == 64:\n",
        "      break\n",
        "    plt.subplot(7, 10, i + 1)\n",
        "    plt.imshow(filter, cmap='gray')\n",
        "    plt.axis(\"off\")\n",
        "  plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "Ixg6Vz6UaV6a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}