{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gzuv2run9Yxa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import gc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#import numpy as\n",
        "import os\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "#from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIR_TRAIN = \"/content/Classification-of-construction-equipment-objects/train/\"\n",
        "DIR_TEST = \"/content/Classification-of-construction-equipment-objects/test/\"\n",
        "\n",
        "PATH_TRAIN = DIR_TRAIN + \"train.csv\"\n",
        "PATH_TEST = DIR_TEST + \"test.csv\""
      ],
      "metadata": {
        "id": "JtcHBYJ9oxVx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/Sergey2110/Classification-of-construction-equipment-objects.git\n",
        "%cd Classification-of-construction-equipment-objects"
      ],
      "metadata": {
        "id": "puFPw94J3f_o",
        "outputId": "edf83ad7-dd43-4547-ba17-692f01707e06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Classification-of-construction-equipment-objects'...\n",
            "remote: Enumerating objects: 7194, done.\u001b[K\n",
            "remote: Counting objects: 100% (7194/7194), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7180/7180), done.\u001b[K\n",
            "remote: Total 7194 (delta 24), reused 7172 (delta 10), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (7194/7194), 27.04 MiB | 27.09 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n",
            "/content/Classification-of-construction-equipment-objects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "8LotOtK-sFsV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, data_df, transform=None):\n",
        "        self.data_df = data_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # достаем имя изображения и ее лейбл\n",
        "        image_name, label = self.data_df.iloc[idx]['ID_img'], self.data_df.iloc[idx]['class']\n",
        "\n",
        "        # читаем картинку. read the image\n",
        "        image = cv2.imread(DIR_TRAIN + f\"{image_name}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        # преобразуем, если нужно. transform it, if necessary\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)"
      ],
      "metadata": {
        "id": "h72XzlyfMZek"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, data_df, transform=None):\n",
        "        self.data_df = data_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.data_df.iloc[idx]['ID_img']\n",
        "\n",
        "        # читаем картинку\n",
        "        image = cv2.imread(DIR_TEST + f\"{image_name}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        # преобразуем, если нужно\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)"
      ],
      "metadata": {
        "id": "7URcg7KlMqbV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classification:\n",
        "    def __init__(self):\n",
        "        print(\"Обучающей выборки \", len(os.listdir(DIR_TRAIN)))\n",
        "        print(\"Тестовой выборки \", len(os.listdir(DIR_TEST)))\n",
        "\n",
        "        gc.collect()\n",
        "        # задаем преобразование изображения.\n",
        "        self.train_transform = transforms.Compose([\n",
        "            # transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        self.valid_transform = transforms.Compose([\n",
        "            # transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        self.data_df = pd.read_csv(PATH_TRAIN)\n",
        "        self.data_df = self.data_df[:10]\n",
        "        # self.data_df.head(3)\n",
        "\n",
        "        # разделим датасет на трейн и валидацию, чтобы смотреть на качество\n",
        "        self.train_df, self.valid_df = train_test_split(self.data_df, test_size=0.2, random_state=43)\n",
        "        train_dataset = ImageDataset(self.train_df, self.train_transform)\n",
        "        valid_dataset = ImageDataset(self.valid_df, self.valid_transform)\n",
        "        print(list(train_dataset))\n",
        "        print(list(valid_dataset))\n",
        "\n",
        "        self.train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                                        batch_size=1,\n",
        "                                                        # shuffle=True,\n",
        "                                                        pin_memory=True,\n",
        "                                                        num_workers=2)\n",
        "\n",
        "        self.valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
        "                                                        batch_size=1,\n",
        "                                                        # shuffle=True,\n",
        "                                                        pin_memory=True,\n",
        "                                                        num_workers=2)\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.dict_acc_for_batch = {\"train\": {}, \"test\": {}}\n",
        "        self.dict_loss_for_batch = {\"train\": {}, \"test\": {}}\n",
        "\n",
        "    def crossvalid(self, res_model=None, criterion=None, optimizer=None, dataset=None, k_fold=5):\n",
        "        train_score = pd.Series()\n",
        "        val_score = pd.Series()\n",
        "\n",
        "        total_size = len(dataset)\n",
        "        fraction = 1 / k_fold\n",
        "        seg = int(total_size * fraction)\n",
        "        # tr:train,val:valid; r:right,l:left;  eg: trrr: right index of right side train subset\n",
        "        # index: [trll,trlr],[vall,valr],[trrl,trrr]\n",
        "        for i in range(k_fold):\n",
        "            trll = 0\n",
        "            trlr = i * seg\n",
        "            vall = trlr\n",
        "            valr = i * seg + seg\n",
        "            trrl = valr\n",
        "            trrr = total_size\n",
        "\n",
        "            train_left_indices = list(range(trll, trlr))\n",
        "            train_right_indices = list(range(trrl, trrr))\n",
        "\n",
        "            train_indices = train_left_indices + train_right_indices\n",
        "            val_indices = list(range(vall, valr))\n",
        "\n",
        "            train_set = torch.utils.data.dataset.Subset(dataset, train_indices)\n",
        "            val_set = torch.utils.data.dataset.Subset(dataset, val_indices)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(train_set, batch_size=50,\n",
        "                                                       shuffle=True, num_workers=4)\n",
        "            val_loader = torch.utils.data.DataLoader(val_set, batch_size=50,\n",
        "                                                     shuffle=True, num_workers=4)\n",
        "            train_acc = self.train(res_model, criterion, optimizer, train_loader, val_loader, 1)\n",
        "            train_score.at[i] = train_acc\n",
        "            # val_acc = valid(res_model, criterion, optimizer, val_loader)\n",
        "            # val_score.at[i] = val_acc\n",
        "\n",
        "        return train_score, val_score\n",
        "\n",
        "    def plot_history(self, train_history, val_history, title = 'loss'):\n",
        "        plt.figure()\n",
        "        plt.title('{}'.format(title))\n",
        "\n",
        "        plt.plot(train_history, label='train', zorder=1)\n",
        "        plt.plot(val_history, label='val', zorder=1)\n",
        "\n",
        "        plt.legend(loc='best')\n",
        "        plt.xlabel('steps')\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    def train(self, criterion, optimizer, train_dataloader, test_dataloader, NUM_EPOCH=15, show_img=False):\n",
        "        train_loss_log = []\n",
        "        val_loss_log = []\n",
        "        train_acc_log = []\n",
        "        val_acc_log = []\n",
        "\n",
        "        train_loss_log_for_batch = []\n",
        "        val_loss_log_for_batch = []\n",
        "        train_acc_log_for_batch = []\n",
        "        val_acc_log_for_batch = []\n",
        "\n",
        "        for epoch in tqdm(range(NUM_EPOCH)):\n",
        "            self.model.train()\n",
        "            train_loss = 0.\n",
        "            train_size = 0\n",
        "            train_pred = 0.\n",
        "\n",
        "            for imgs, labels in train_dataloader:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                imgs = imgs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                y_pred = self.model(imgs)\n",
        "\n",
        "                loss = criterion(y_pred, labels)\n",
        "                loss.backward()\n",
        "\n",
        "                train_size += y_pred.size(0)\n",
        "                train_loss += loss.item()\n",
        "                train_loss_log_for_batch.append(loss.data / y_pred.size(0))\n",
        "                train_pred += (y_pred.argmax(1) == labels).sum()\n",
        "                train_acc_log_for_batch.append(train_pred / y_pred.size(0))\n",
        "                optimizer.step()\n",
        "\n",
        "            train_loss_log.append(train_loss / train_size)\n",
        "            train_acc_log.append(train_pred.item() / train_size)\n",
        "\n",
        "            self.dict_loss_for_batch[\"train\"].update({epoch: train_loss_log_for_batch[:]})\n",
        "            self.dict_acc_for_batch[\"train\"].update({epoch: train_acc_log_for_batch[:]})\n",
        "\n",
        "            # if show_img and epoch > (epoch - 2) and train_pred / train_size < 0.9:\n",
        "            #     for j in range(4):\n",
        "            #         show_input(imgs[j].cpu(),\n",
        "            #                    title=f\"{labels[j]} {list_file[list_index_val[j + i * batch_size_v]][0]}\")\n",
        "            #         print(f\" epoch = {epoch} acc = {(train_pred / train_size) / batch_size_v}\")\n",
        "\n",
        "            val_loss = 0.\n",
        "            val_size = 0\n",
        "            val_pred = 0.\n",
        "            self.model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for imgs, labels in test_dataloader:\n",
        "                    imgs = imgs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "\n",
        "                    pred = self.model(imgs)\n",
        "                    loss = criterion(pred, labels)\n",
        "\n",
        "                    val_size += pred.size(0)\n",
        "                    val_loss += loss.item()\n",
        "                    val_loss_log_for_batch.append(loss.data / pred.size(0))\n",
        "                    val_pred += (pred.argmax(1) == labels).sum()\n",
        "                    val_acc_log_for_batch.append(val_pred / pred.size(0))\n",
        "\n",
        "            val_loss_log.append(val_loss / val_size)\n",
        "            val_acc_log.append(val_pred.item() / val_size)\n",
        "\n",
        "            self.dict_loss_for_batch[\"test\"].update({epoch: val_loss_log_for_batch[:]})\n",
        "            self.dict_acc_for_batch[\"test\"].update({epoch: val_acc_log_for_batch[:]})\n",
        "\n",
        "        # clear_output()\n",
        "        # self.plot_history(train_loss_log, val_loss_log, 'loss')\n",
        "\n",
        "        # print('Train loss:', (train_loss / train_size) * 100)\n",
        "        # print('Val loss:', (val_loss / val_size) * 100)\n",
        "        # print('Train acc:', (train_pred.item() / train_size) * 100)\n",
        "        # print('Val acc:', (val_pred.item() / val_size) * 100)\n",
        "\n",
        "        return train_loss_log, train_acc_log, val_loss_log, val_acc_log\n",
        "\n",
        "    def watch_img(self):\n",
        "        # посмотрим на картинки. Не забудем указать корретный путь до папки\n",
        "        sns.countplot(x=\"class\", data=self.data_df)\n",
        "        fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
        "        fig.suptitle(f'Автомобиль {\" \" * 105} Кран', fontsize=14)\n",
        "\n",
        "        for i, name in zip(range(4), self.data_df[self.data_df['class'] == 1].sample(4, random_state=42)['ID_img']):\n",
        "            img = plt.imread(DIR_TRAIN + f\"{name}\")\n",
        "            axs[i // 2, (i % 2)].imshow(img)\n",
        "            axs[i // 2, (i % 2)].axis('off')\n",
        "\n",
        "        for i, name in zip(range(4), self.data_df[self.data_df['class'] == 0].sample(4, random_state=42)['ID_img']):\n",
        "            img = plt.imread(DIR_TRAIN + f\"{name}\")\n",
        "            axs[i // 2, (i % 2) + 2].imshow(img)\n",
        "            axs[i // 2, (i % 2) + 2].axis('off')\n",
        "\n",
        "        fig.tight_layout()\n",
        "        fig.subplots_adjust(top=0.88)\n",
        "\n",
        "    def train_model(self):\n",
        "        self.model = models.resnet152(pretrained=True)\n",
        "        self.model.fc = nn.Linear(2048, 8)\n",
        "        self.model = self.model.to(self.device)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=0.01)\n",
        "        train_loss_log, train_acc_log, val_loss_log, val_acc_log = self.train(criterion,\n",
        "                                                                              optimizer,\n",
        "                                                                              self.train_loader,\n",
        "                                                                              self.valid_loader,\n",
        "                                                                              1)\n",
        "        return train_loss_log, train_acc_log, val_loss_log, val_acc_log\n",
        "\n",
        "    def evaluation_model(self):\n",
        "        valid_predicts = []\n",
        "        self.model.eval()\n",
        "        for imgs, _ in tqdm(self.valid_loader):\n",
        "            imgs = imgs.to(self.device)\n",
        "            pred = self.model(imgs)\n",
        "            pred_numpy = pred.cpu().detach().numpy()\n",
        "            for class_obj in pred_numpy:\n",
        "                index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
        "                valid_predicts.append(index)\n",
        "        self.valid_df[\"pred\"] = valid_predicts\n",
        "        val_accuracy = recall_score(self.valid_df['class'].values, self.valid_df['pred'].values, average=\"macro\")\n",
        "        print(f\"Validation accuracy = {val_accuracy}\")\n",
        "\n",
        "        self.test_df = pd.read_csv(PATH_TEST)\n",
        "        self.test_df = self.test_df.drop([\"class\"], axis=1)\n",
        "        self.test_dataset = TestImageDataset(self.test_df, self.valid_transform)\n",
        "        self.test_loader = torch.utils.data.DataLoader(dataset=self.test_dataset,\n",
        "                                                       batch_size=32,\n",
        "                                                       # shuffle=True,\n",
        "                                                       pin_memory=True,\n",
        "                                                       num_workers=2)\n",
        "\n",
        "    def create_submit(self):\n",
        "        self.model.eval()\n",
        "        predicts = []\n",
        "        for imgs in tqdm(self.test_loader):\n",
        "            imgs = imgs.to(self.device)\n",
        "            pred = self.model(imgs)\n",
        "            for class_obj in pred:\n",
        "                index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])\n",
        "                predicts.append(index)\n",
        "\n",
        "        self.test_df[\"class\"] = predicts\n",
        "        self.test_df.head()\n",
        "        self.test_df.to_csv(\"submit.csv\", index=False)"
      ],
      "metadata": {
        "id": "WTzOYXnLr615"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification = Classification()\n",
        "acc_loss = classification.train_model()\n",
        "# classification.evaluation_model()\n",
        "# classification.create_submit()"
      ],
      "metadata": {
        "id": "NtXeREGor-ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a361ee27-58de-47e6-dcdc-78ac30ed5cf6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающей выборки  4993\n",
            "Тестовой выборки  2141\n",
            "[(tensor([[[ 0.8618,  0.8618,  0.8618,  ..., -0.8849, -0.8849, -0.8849],\n",
            "         [ 0.8618,  0.8618,  0.8618,  ..., -0.8849, -0.8849, -0.8849],\n",
            "         [ 0.8618,  0.8618,  0.8618,  ..., -0.8849, -0.8849, -0.8849],\n",
            "         ...,\n",
            "         [-0.7650, -0.7650, -0.7650,  ..., -1.1247, -1.1247, -1.1247],\n",
            "         [-0.7650, -0.7650, -0.7650,  ..., -1.1760, -1.1760, -1.1760],\n",
            "         [-0.7650, -0.7650, -0.7650,  ..., -1.1760, -1.1760, -1.1760]],\n",
            "\n",
            "        [[ 0.8529,  0.8529,  0.8529,  ..., -0.7227, -0.7227, -0.7227],\n",
            "         [ 0.8529,  0.8529,  0.8529,  ..., -0.7227, -0.7227, -0.7227],\n",
            "         [ 0.8529,  0.8529,  0.8529,  ..., -0.7227, -0.7227, -0.7227],\n",
            "         ...,\n",
            "         [-0.6702, -0.6702, -0.6702,  ..., -0.9328, -0.9328, -0.9328],\n",
            "         [-0.6702, -0.6702, -0.6702,  ..., -0.9853, -0.9853, -0.9853],\n",
            "         [-0.6702, -0.6702, -0.6702,  ..., -0.9853, -0.9853, -0.9853]],\n",
            "\n",
            "        [[ 0.9494,  0.9494,  0.9494,  ..., -0.6193, -0.6193, -0.6193],\n",
            "         [ 0.9494,  0.9494,  0.9494,  ..., -0.6193, -0.6193, -0.6193],\n",
            "         [ 0.9494,  0.9494,  0.9494,  ..., -0.6193, -0.6193, -0.6193],\n",
            "         ...,\n",
            "         [-0.4798, -0.4798, -0.4798,  ..., -0.6367, -0.6367, -0.6367],\n",
            "         [-0.4798, -0.4798, -0.4798,  ..., -0.6890, -0.6890, -0.6890],\n",
            "         [-0.4798, -0.4798, -0.4798,  ..., -0.6890, -0.6890, -0.6890]]]), tensor(4)), (tensor([[[ 0.2624,  0.2624,  0.2624,  ...,  1.3927,  1.3927,  1.3927],\n",
            "         [ 0.2624,  0.2624,  0.2624,  ...,  1.3927,  1.3927,  1.3927],\n",
            "         [ 0.2624,  0.2624,  0.2624,  ...,  1.3927,  1.3927,  1.3927],\n",
            "         ...,\n",
            "         [ 1.7694,  1.7694,  1.7694,  ...,  1.7180,  1.7180,  1.7180],\n",
            "         [ 1.7694,  1.7694,  1.7694,  ...,  1.7180,  1.7180,  1.7180],\n",
            "         [ 1.7694,  1.7694,  1.7694,  ...,  1.7180,  1.7180,  1.7180]],\n",
            "\n",
            "        [[-0.4601, -0.4601, -0.4601,  ...,  0.4328,  0.4328,  0.4328],\n",
            "         [-0.4601, -0.4601, -0.4601,  ...,  0.4328,  0.4328,  0.4328],\n",
            "         [-0.4601, -0.4601, -0.4601,  ...,  0.4328,  0.4328,  0.4328],\n",
            "         ...,\n",
            "         [ 1.4132,  1.4132,  1.4132,  ...,  1.2731,  1.2731,  1.2731],\n",
            "         [ 1.4132,  1.4132,  1.4132,  ...,  1.2731,  1.2731,  1.2731],\n",
            "         [ 1.4132,  1.4132,  1.4132,  ...,  1.2731,  1.2731,  1.2731]],\n",
            "\n",
            "        [[-1.2467, -1.2467, -1.2467,  ..., -0.8807, -0.8807, -0.8807],\n",
            "         [-1.2467, -1.2467, -1.2467,  ..., -0.8807, -0.8807, -0.8807],\n",
            "         [-1.2467, -1.2467, -1.2467,  ..., -0.8807, -0.8807, -0.8807],\n",
            "         ...,\n",
            "         [ 1.4374,  1.4374,  1.4374,  ...,  1.3851,  1.3851,  1.3851],\n",
            "         [ 1.4374,  1.4374,  1.4374,  ...,  1.3851,  1.3851,  1.3851],\n",
            "         [ 1.4374,  1.4374,  1.4374,  ...,  1.3851,  1.3851,  1.3851]]]), tensor(1)), (tensor([[[ 0.3138,  0.3138,  0.2967,  ...,  0.8447,  0.8447,  0.8447],\n",
            "         [ 0.2282,  0.2282,  0.2282,  ...,  0.8447,  0.8447,  0.8447],\n",
            "         [-0.1999, -0.1999, -0.1486,  ...,  0.7933,  0.7933,  0.7933],\n",
            "         ...,\n",
            "         [-1.2617, -1.2617, -1.1932,  ..., -1.0219, -0.8335, -0.8335],\n",
            "         [-1.1760, -1.1760, -1.0904,  ..., -1.2788, -1.0733, -1.0733],\n",
            "         [-1.1589, -1.1589, -1.0733,  ..., -1.3302, -1.1247, -1.1247]],\n",
            "\n",
            "        [[ 0.3452,  0.3452,  0.2927,  ...,  1.0280,  1.0280,  1.0280],\n",
            "         [ 0.2752,  0.2752,  0.2227,  ...,  1.0280,  1.0280,  1.0280],\n",
            "         [-0.1625, -0.1625, -0.1450,  ...,  0.9930,  0.9930,  0.9930],\n",
            "         ...,\n",
            "         [-1.0378, -1.0378, -0.9678,  ..., -1.0378, -0.8452, -0.8452],\n",
            "         [-0.9853, -0.9853, -0.8978,  ..., -1.3004, -1.0903, -1.0903],\n",
            "         [-0.9678, -0.9678, -0.8803,  ..., -1.3529, -1.1429, -1.1429]],\n",
            "\n",
            "        [[ 0.3568,  0.3568,  0.3219,  ...,  1.4548,  1.4548,  1.4548],\n",
            "         [ 0.2871,  0.2871,  0.2522,  ...,  1.4548,  1.4548,  1.4548],\n",
            "         [-0.1487, -0.1487, -0.1138,  ...,  1.4200,  1.4200,  1.4200],\n",
            "         ...,\n",
            "         [-0.5147, -0.5147, -0.4450,  ..., -0.9156, -0.7238, -0.7238],\n",
            "         [-0.4275, -0.4275, -0.3404,  ..., -1.1770, -0.9678, -0.9678],\n",
            "         [-0.4101, -0.4101, -0.3230,  ..., -1.2293, -1.0201, -1.0201]]]), tensor(3)), (tensor([[[ 1.4098,  1.4098,  1.4098,  ..., -0.1486, -0.1486, -0.1486],\n",
            "         [ 1.4098,  1.4098,  1.4098,  ..., -0.1486, -0.1486, -0.1486],\n",
            "         [ 1.4269,  1.4269,  1.4269,  ..., -0.0629, -0.0629, -0.0629],\n",
            "         ...,\n",
            "         [ 1.7009,  1.7009,  1.7009,  ...,  0.9474,  0.9474,  0.9474],\n",
            "         [ 1.7009,  1.7009,  1.7009,  ...,  0.9474,  0.9474,  0.9474],\n",
            "         [ 1.7009,  1.7009,  1.7009,  ...,  0.9474,  0.9474,  0.9474]],\n",
            "\n",
            "        [[-0.7927, -0.7927, -0.7927,  ..., -0.6001, -0.6001, -0.6001],\n",
            "         [-0.7927, -0.7927, -0.7927,  ..., -0.6001, -0.6001, -0.6001],\n",
            "         [-0.7752, -0.7752, -0.7752,  ..., -0.5126, -0.5126, -0.5126],\n",
            "         ...,\n",
            "         [ 1.0805,  1.0805,  1.0805,  ...,  0.5203,  0.5203,  0.5203],\n",
            "         [ 1.0805,  1.0805,  1.0805,  ...,  0.5203,  0.5203,  0.5203],\n",
            "         [ 1.0805,  1.0805,  1.0805,  ...,  0.5203,  0.5203,  0.5203]],\n",
            "\n",
            "        [[-1.3861, -1.3861, -1.3861,  ..., -0.5321, -0.5321, -0.5321],\n",
            "         [-1.3861, -1.3861, -1.3861,  ..., -0.5321, -0.5321, -0.5321],\n",
            "         [-1.3687, -1.3687, -1.3687,  ..., -0.4624, -0.4624, -0.4624],\n",
            "         ...,\n",
            "         [ 0.5659,  0.5659,  0.5659,  ..., -0.0441, -0.0441, -0.0441],\n",
            "         [ 0.5659,  0.5659,  0.5659,  ..., -0.0441, -0.0441, -0.0441],\n",
            "         [ 0.5659,  0.5659,  0.5659,  ..., -0.0441, -0.0441, -0.0441]]]), tensor(4)), (tensor([[[ 1.2728,  1.2728,  1.2728,  ...,  0.9817,  0.9817,  0.9817],\n",
            "         [ 1.2728,  1.2728,  1.2728,  ...,  0.9817,  0.9817,  0.9817],\n",
            "         [ 1.2728,  1.2728,  1.2728,  ...,  0.9817,  0.9817,  0.9817],\n",
            "         ...,\n",
            "         [-0.2513, -0.2513, -0.2513,  ..., -1.1075, -1.0733, -1.0733],\n",
            "         [-0.2513, -0.2513, -0.2513,  ..., -1.1589, -1.1418, -1.1418],\n",
            "         [-0.2513, -0.2513, -0.2513,  ..., -1.1589, -1.1418, -1.1418]],\n",
            "\n",
            "        [[ 1.7108,  1.7108,  1.7108,  ...,  1.3957,  1.3957,  1.3957],\n",
            "         [ 1.7108,  1.7108,  1.7108,  ...,  1.3957,  1.3957,  1.3957],\n",
            "         [ 1.7108,  1.7108,  1.7108,  ...,  1.3957,  1.3957,  1.3957],\n",
            "         ...,\n",
            "         [-0.5476, -0.5476, -0.5476,  ..., -1.0903, -1.0728, -1.0728],\n",
            "         [-0.5476, -0.5476, -0.5476,  ..., -1.1604, -1.1429, -1.1429],\n",
            "         [-0.5476, -0.5476, -0.5476,  ..., -1.1604, -1.1429, -1.1429]],\n",
            "\n",
            "        [[ 2.1868,  2.1868,  2.1868,  ...,  1.9428,  1.9428,  1.9428],\n",
            "         [ 2.1868,  2.1868,  2.1868,  ...,  1.9428,  1.9428,  1.9428],\n",
            "         [ 2.1868,  2.1868,  2.1868,  ...,  1.9428,  1.9428,  1.9428],\n",
            "         ...,\n",
            "         [-0.7761, -0.7761, -0.7761,  ..., -1.0898, -1.0550, -1.0550],\n",
            "         [-0.7761, -0.7761, -0.7761,  ..., -1.1596, -1.1247, -1.1247],\n",
            "         [-0.7761, -0.7761, -0.7761,  ..., -1.1596, -1.1247, -1.1247]]]), tensor(6)), (tensor([[[2.2318, 2.2318, 2.2318,  ..., 2.2318, 2.2318, 2.2318],\n",
            "         [2.2318, 2.2318, 2.2318,  ..., 2.2318, 2.2318, 2.2318],\n",
            "         [2.2318, 2.2318, 2.2318,  ..., 2.2318, 2.2318, 2.2318],\n",
            "         ...,\n",
            "         [2.2318, 2.2318, 2.2318,  ..., 2.2318, 2.2318, 2.2318],\n",
            "         [2.2318, 2.2318, 2.2318,  ..., 2.2318, 2.2318, 2.2318],\n",
            "         [2.2318, 2.2318, 2.2318,  ..., 2.2318, 2.2318, 2.2318]],\n",
            "\n",
            "        [[2.4111, 2.4111, 2.4111,  ..., 2.4111, 2.4111, 2.4111],\n",
            "         [2.4111, 2.4111, 2.4111,  ..., 2.4111, 2.4111, 2.4111],\n",
            "         [2.4111, 2.4111, 2.4111,  ..., 2.4111, 2.4111, 2.4111],\n",
            "         ...,\n",
            "         [2.4111, 2.4111, 2.4111,  ..., 2.4111, 2.4111, 2.4111],\n",
            "         [2.4111, 2.4111, 2.4111,  ..., 2.4111, 2.4111, 2.4111],\n",
            "         [2.4111, 2.4111, 2.4111,  ..., 2.4111, 2.4111, 2.4111]],\n",
            "\n",
            "        [[2.6226, 2.6226, 2.6226,  ..., 2.6226, 2.6226, 2.6226],\n",
            "         [2.6226, 2.6226, 2.6226,  ..., 2.6226, 2.6226, 2.6226],\n",
            "         [2.6226, 2.6226, 2.6226,  ..., 2.6226, 2.6226, 2.6226],\n",
            "         ...,\n",
            "         [2.6226, 2.6226, 2.6226,  ..., 2.6226, 2.6226, 2.6226],\n",
            "         [2.6226, 2.6226, 2.6226,  ..., 2.6226, 2.6226, 2.6226],\n",
            "         [2.6226, 2.6226, 2.6226,  ..., 2.6226, 2.6226, 2.6226]]]), tensor(4)), (tensor([[[ 1.6153,  1.6153,  1.6324,  ...,  1.7865,  1.7865,  1.7865],\n",
            "         [ 1.6324,  1.6324,  1.6495,  ...,  1.7865,  1.7865,  1.7865],\n",
            "         [ 1.6838,  1.6838,  1.7009,  ...,  1.7694,  1.7694,  1.7694],\n",
            "         ...,\n",
            "         [ 0.1939,  0.2111,  0.3309,  ...,  1.6153,  1.5639,  1.5639],\n",
            "         [ 0.0398,  0.0569,  0.1939,  ...,  1.5639,  1.5125,  1.5125],\n",
            "         [ 0.0227,  0.0398,  0.1768,  ...,  1.5639,  1.4954,  1.4954]],\n",
            "\n",
            "        [[ 1.9734,  1.9734,  1.9909,  ...,  2.0959,  2.0959,  2.0959],\n",
            "         [ 1.9909,  1.9909,  2.0084,  ...,  2.0959,  2.0959,  2.0959],\n",
            "         [ 2.0434,  2.0434,  2.0609,  ...,  2.0784,  2.0784,  2.0784],\n",
            "         ...,\n",
            "         [ 0.2227,  0.2227,  0.3452,  ...,  1.5357,  1.4657,  1.4657],\n",
            "         [ 0.0826,  0.0826,  0.2227,  ...,  1.4832,  1.4132,  1.4132],\n",
            "         [ 0.0651,  0.0651,  0.2052,  ...,  1.4832,  1.4132,  1.4132]],\n",
            "\n",
            "        [[ 2.2217,  2.2217,  2.2391,  ...,  2.3437,  2.3437,  2.3437],\n",
            "         [ 2.2391,  2.2391,  2.2566,  ...,  2.3437,  2.3437,  2.3437],\n",
            "         [ 2.2914,  2.2914,  2.3088,  ...,  2.3263,  2.3263,  2.3263],\n",
            "         ...,\n",
            "         [-0.6541, -0.6541, -0.5147,  ...,  1.2805,  1.2282,  1.2282],\n",
            "         [-0.8284, -0.8284, -0.6890,  ...,  1.2457,  1.1759,  1.1759],\n",
            "         [-0.8633, -0.8458, -0.7064,  ...,  1.2457,  1.1759,  1.1759]]]), tensor(4)), (tensor([[[-0.6794, -0.6794, -0.6794,  ...,  0.6221,  0.6221,  0.6221],\n",
            "         [-0.6794, -0.6794, -0.6794,  ...,  0.6221,  0.6221,  0.6221],\n",
            "         [-0.6794, -0.6794, -0.6794,  ...,  0.6221,  0.6221,  0.6221],\n",
            "         ...,\n",
            "         [-0.6965, -0.6965, -0.6965,  ..., -0.5596, -0.5596, -0.5596],\n",
            "         [-0.6965, -0.6965, -0.6965,  ..., -0.5596, -0.5596, -0.5596],\n",
            "         [-0.6965, -0.6965, -0.6965,  ..., -0.5596, -0.5596, -0.5596]],\n",
            "\n",
            "        [[-0.7577, -0.7577, -0.7577,  ...,  0.7304,  0.7304,  0.7304],\n",
            "         [-0.7577, -0.7577, -0.7577,  ...,  0.7304,  0.7304,  0.7304],\n",
            "         [-0.7577, -0.7577, -0.7577,  ...,  0.7304,  0.7304,  0.7304],\n",
            "         ...,\n",
            "         [-0.7052, -0.7052, -0.7052,  ..., -0.5126, -0.5126, -0.5126],\n",
            "         [-0.7052, -0.7052, -0.7052,  ..., -0.5126, -0.5126, -0.5126],\n",
            "         [-0.7052, -0.7052, -0.7052,  ..., -0.5126, -0.5126, -0.5126]],\n",
            "\n",
            "        [[-0.6367, -0.6367, -0.6367,  ...,  1.0365,  1.0365,  1.0365],\n",
            "         [-0.6367, -0.6367, -0.6367,  ...,  1.0365,  1.0365,  1.0365],\n",
            "         [-0.6367, -0.6367, -0.6367,  ...,  1.0365,  1.0365,  1.0365],\n",
            "         ...,\n",
            "         [-0.5844, -0.5844, -0.5844,  ..., -0.4450, -0.4450, -0.4450],\n",
            "         [-0.5844, -0.5844, -0.5844,  ..., -0.4450, -0.4450, -0.4450],\n",
            "         [-0.5844, -0.5844, -0.5844,  ..., -0.4450, -0.4450, -0.4450]]]), tensor(3))]\n",
            "[(tensor([[[1.6838, 1.6838, 1.6838,  ..., 1.4954, 1.4783, 1.4783],\n",
            "         [1.6838, 1.6838, 1.6838,  ..., 1.4954, 1.4783, 1.4783],\n",
            "         [1.6838, 1.6838, 1.6838,  ..., 1.6153, 1.6153, 1.6153],\n",
            "         ...,\n",
            "         [1.8037, 1.8037, 1.8037,  ..., 1.9235, 1.9064, 1.9064],\n",
            "         [1.8037, 1.8037, 1.8037,  ..., 1.9064, 1.9064, 1.9064],\n",
            "         [1.8037, 1.8037, 1.8037,  ..., 1.9064, 1.9064, 1.9064]],\n",
            "\n",
            "        [[1.5182, 1.5182, 1.5182,  ..., 0.4853, 0.4503, 0.4503],\n",
            "         [1.5182, 1.5182, 1.5182,  ..., 0.4853, 0.4503, 0.4503],\n",
            "         [1.5182, 1.5182, 1.5182,  ..., 0.6254, 0.5903, 0.5903],\n",
            "         ...,\n",
            "         [1.5882, 1.5882, 1.5882,  ..., 1.6758, 1.6758, 1.6758],\n",
            "         [1.5707, 1.5707, 1.5707,  ..., 1.6758, 1.6758, 1.6758],\n",
            "         [1.5707, 1.5707, 1.5707,  ..., 1.6758, 1.6758, 1.6758]],\n",
            "\n",
            "        [[1.1585, 1.1585, 1.1411,  ..., 0.4788, 0.4439, 0.4439],\n",
            "         [1.1585, 1.1585, 1.1411,  ..., 0.4788, 0.4439, 0.4439],\n",
            "         [1.1585, 1.1585, 1.1411,  ..., 0.6008, 0.5659, 0.5659],\n",
            "         ...,\n",
            "         [1.2805, 1.2805, 1.2805,  ..., 1.3677, 1.3677, 1.3677],\n",
            "         [1.2457, 1.2457, 1.2457,  ..., 1.3502, 1.3502, 1.3502],\n",
            "         [1.2457, 1.2457, 1.2457,  ..., 1.3502, 1.3502, 1.3502]]]), tensor(6)), (tensor([[[-0.4911, -0.4911, -0.4739,  ...,  1.3584,  1.3755,  1.3755],\n",
            "         [-0.4911, -0.4911, -0.4739,  ...,  1.3584,  1.3755,  1.3755],\n",
            "         [-0.4739, -0.4739, -0.4568,  ...,  1.3070,  1.3242,  1.3242],\n",
            "         ...,\n",
            "         [ 0.8618,  0.8618,  0.8789,  ..., -1.0390, -1.0390, -1.0390],\n",
            "         [ 0.8618,  0.8618,  0.8789,  ..., -1.0390, -1.0390, -1.0390],\n",
            "         [ 0.8618,  0.8618,  0.8789,  ..., -1.0390, -1.0390, -1.0390]],\n",
            "\n",
            "        [[-0.3901, -0.3901, -0.3725,  ...,  1.7108,  1.7108,  1.7108],\n",
            "         [-0.3901, -0.3901, -0.3725,  ...,  1.7108,  1.7108,  1.7108],\n",
            "         [-0.3725, -0.3725, -0.3550,  ...,  1.6583,  1.6583,  1.6583],\n",
            "         ...,\n",
            "         [ 0.9930,  0.9930,  1.0105,  ..., -0.7927, -0.7927, -0.7927],\n",
            "         [ 0.9930,  0.9930,  1.0105,  ..., -0.7927, -0.7927, -0.7927],\n",
            "         [ 0.9930,  0.9930,  1.0105,  ..., -0.7927, -0.7927, -0.7927]],\n",
            "\n",
            "        [[-0.0790, -0.0790, -0.0615,  ...,  1.9603,  1.9603,  1.9603],\n",
            "         [-0.0790, -0.0790, -0.0615,  ...,  1.9603,  1.9603,  1.9603],\n",
            "         [-0.0615, -0.0615, -0.0441,  ...,  1.9080,  1.9080,  1.9080],\n",
            "         ...,\n",
            "         [ 1.1411,  1.1411,  1.1585,  ..., -0.3753, -0.3753, -0.3753],\n",
            "         [ 1.1411,  1.1411,  1.1585,  ..., -0.3753, -0.3753, -0.3753],\n",
            "         [ 1.1411,  1.1411,  1.1585,  ..., -0.3753, -0.3753, -0.3753]]]), tensor(1))]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n"
          ]
        }
      ]
    }
  ]
}